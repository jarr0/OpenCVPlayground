[
  {
    "id": "3020960c0eb948b194758e23d0f81e63",
    "func_name": "cvtColor",
    "function": "void cvtColor( InputArray src, OutputArray dst, int code, int dstCn = 0 );",
    "brief_description": "Converts an image from one color space to another.",
    "long_description": "The function converts an input image from one color space to another. In case of a transformation to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.  The conventional ranges for R, G, and B channel values are: -   0 to 255 for CV_8U images -   0 to 65535 for CV_16U images -   0 to 1 for CV_32F images  In case of linear transformations, the range does not matter. But in case of a non-linear transformation, an input RGB image should be normalized to the proper value range to get the correct results, for example, for RGB \\f$\\rightarrow\\f$ L\\*u\\*v\\* transformation. For example, if you have a 32-bit floating-point image directly converted from an 8-bit image without any scaling, then it will have the 0..255 value range instead of 0..1 assumed by the function. So, before calling #cvtColor , you need first to scale the image down: @code     img *= 1./255;     cvtColor(img, img, COLOR_BGR2Luv); @endcode If you use #cvtColor with 8-bit images, the conversion will have some information lost. For many applications, this will not be noticeable but it is recommended to use 32-bit images in applications that need the full range of colors or that convert an image before an operation and then convert back.  If conversion adds the alpha channel, its value will set to the maximum of corresponding channel range: 255 for CV_8U, 65535 for CV_16U, 1 for CV_32F.",
    "return_type": "void",
    "signature": [
      {
        "param_no": 0,
        "param_name": "src",
        "var_desc": "input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC... ), or single-precision floating-point.",
        "var_type": "InputArray"
      },
      {
        "param_no": 1,
        "param_name": "dst",
        "var_desc": "output image of the same size and depth as src.",
        "var_type": "OutputArray"
      },
      {
        "param_no": 2,
        "param_name": "code",
        "var_desc": "color space conversion code (see #ColorConversionCodes).",
        "var_type": "dropdown:enum",
        "enum_name": "ColorConversionCodes"
      },
      {
        "param_no": 3,
        "param_name": "dstCn",
        "var_desc": "number of channels in the destination image; if the parameter is 0, the number of the channels is derived automatically from src and code.",
        "var_type": "int",
        "default_value": "0"
      }
    ]
  },
  {
    "id": "55fe065727e3411586689f26c66e03cc",
    "func_name": "boxFilter",
    "function": "void boxFilter( InputArray src, OutputArray dst, int ddepth, Size ksize, Point anchor = Point(-1,-1), bool normalize = true, int borderType = BORDER_DEFAULT );",
    "brief_description": "Blurs an image using the box filter.",
    "long_description": "The function smooths an image using the kernel:  \\f[\\texttt{K} =  \\alpha \\begin{bmatrix} 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1  \\\\ \\hdotsfor{6} \\\\ 1 & 1 & 1 &  \\cdots & 1 & 1 \\end{bmatrix}\\f]  where  \\f[\\alpha = \\begin{cases} \\frac{1}{\\texttt{ksize.width*ksize.height}} & \\texttt{when } \\texttt{normalize=true}  \\\\1 & \\texttt{otherwise}\\end{cases}\\f]  Unnormalized box filter is useful for computing various integral characteristics over each pixel neighborhood, such as covariance matrices of image derivatives (used in dense optical flow algorithms, and so on). If you need to compute pixel sums over variable-size windows, use #integral.",
    "return_type": "void",
    "signature": [
      {
        "param_no": 0,
        "param_name": "src",
        "var_desc": "input image.",
        "var_type": "InputArray"
      },
      {
        "param_no": 1,
        "param_name": "dst",
        "var_desc": "output image of the same size and type as src.",
        "var_type": "OutputArray"
      },
      {
        "param_no": 2,
        "param_name": "ddepth",
        "var_desc": "the output image depth (-1 to use src.depth()).",
        "var_type": "int"
      },
      {
        "param_no": 3,
        "param_name": "ksize",
        "var_desc": "blurring kernel size.",
        "var_type": "Size"
      },
      {
        "param_no": 4,
        "param_name": "anchor",
        "var_desc": "anchor point; default value Point(-1,-1) means that the anchor is at the kernel center.",
        "var_type": "Point"
      },
      {
        "param_no": 5,
        "param_name": "normalize",
        "var_desc": "flag, specifying whether the kernel is normalized by its area or not.",
        "var_type": "bool",
        "default_value": "true"
      },
      {
        "param_no": 6,
        "param_name": "borderType",
        "var_desc": "border mode used to extrapolate pixels outside of the image, see #BorderTypes. #BORDER_WRAP is not supported. @sa  blur, bilateralFilter, GaussianBlur, medianBlur, integral",
        "var_type": "dropdown:enum",
        "enum_name": "BorderTypes",
        "default_value": "BORDER_DEFAULT"
      }
    ]
  },
  {
    "id": "2256feb177094cf698ab0e3127004385",
    "func_name": "sqrBoxFilter",
    "function": "void sqrBoxFilter( InputArray src, OutputArray dst, int ddepth, Size ksize, Point anchor = Point(-1, -1), bool normalize = true, int borderType = BORDER_DEFAULT );",
    "brief_description": "Calculates the normalized sum of squares of the pixel values overlapping the filter.",
    "long_description": "For every pixel \\f$ (x, y) \\f$ in the source image, the function calculates the sum of squares of those neighboring pixel values which overlap the filter placed over the pixel \\f$ (x, y) \\f$.  The unnormalized square box filter can be useful in computing local image statistics such as the the local variance and standard deviation around the neighborhood of a pixel.",
    "return_type": "void",
    "signature": [
      {
        "param_no": 0,
        "param_name": "src",
        "var_desc": "input image",
        "var_type": "InputArray"
      },
      {
        "param_no": 1,
        "param_name": "dst",
        "var_desc": "output image of the same size and type as src",
        "var_type": "OutputArray"
      },
      {
        "param_no": 2,
        "param_name": "ddepth",
        "var_desc": "the output image depth (-1 to use src.depth())",
        "var_type": "int"
      },
      {
        "param_no": 3,
        "param_name": "ksize",
        "var_desc": "kernel size",
        "var_type": "Size"
      },
      {
        "param_no": 4,
        "param_name": "anchor",
        "var_desc": "kernel anchor point. The default value of Point(-1, -1) denotes that the anchor is at the kernel center.",
        "var_type": "Point"
      },
      {
        "param_no": 5,
        "param_name": "normalize",
        "var_desc": "flag, specifying whether the kernel is to be normalized by it's area or not.",
        "var_type": "bool",
        "default_value": "true"
      },
      {
        "param_no": 6,
        "param_name": "borderType",
        "var_desc": "border mode used to extrapolate pixels outside of the image, see #BorderTypes. #BORDER_WRAP is not supported. @sa boxFilter",
        "var_type": "dropdown:enum",
        "enum_name": "BorderTypes",
        "default_value": "BORDER_DEFAULT"
      }
    ]
  }
]
